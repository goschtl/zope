================
Introducing ZODB
================

ZODB provides an object-persistence facility for Python.  It provides
many features, which we'll get into later, but first, let's take a
very quick look at the basics.

.. contents::

Getting started
===============

We start by creating a file-based database:

    >>> import ZODB
    >>> conn = ZODB.connection('data.fs')

The connection function opens a database and returns a connection to it.
Because the database didn't already exist, it's created automatically.

Initially, the database contains a single object, the root object.
Connections have a root attribute that retrieves the root object [#root_]:

    >>> conn.root
    <root >

When using the ZODB, we always start with the root object and use it
to access other objects.  The root object is an object that you
can add items to to store your own data.

To store data in the database, you must use "persistent" objects.  To
create a persistent object, start by creating a class that subclasses
persistent.Persistent.  Let's create a database to manage books and
authors. We'll start by creating a book module that defines the
classes we'll use::

    import persistent, BTrees.OOBTree

    class Book(persistent.Persistent):
        def __init__(self, title):
            self.title = title

    class Author(persistent.Persistent):
        def __init__(self, id, name):
            self.id = id
            self.name = name
            self.books = BTrees.OOBTree.OOBTree()

        def new_book(self, title):
            book = Book(title)
            book.author = self
            self.books[title] = book
            return book

The OOBTree class implements a persistent mapping object that keeps
its keys sorted.

Now, we'll use the book module we created to store books in our database:

    >>> import book, BTrees.OOBTree
    >>> conn.root.authors = BTrees.OOBTree.OOBTree()
    >>> conn.root.books = BTrees.OOBTree.OOBTree()

    >>> author = book.Author('tolkien', 'J.R.R. Tolkien')
    >>> conn.root.authors[author.id] = author
    >>> for title in ["The Fellowship of the Ring",
    ...               "The Two Towers",
    ...               "The return of the King"]:
    ...     conn.root.books[title] = author.new_book[title]

In the root of our database, we added a collection of authors
arranged by author name, and a collection of books arranged by
book title.

So, now we have a small database with 3 books and an author.  We can
query it by author or by book using Python as our query language:

    >>> conn.books["The Two Towers"].author.name
    'J.R.R. Tolkien'

We used BTrees to implement the books and authors collections. BTrees
have a number of advantages and limitations:

- BTrees are highly scalable and are therefore appropriate for
  collections contain large number of items.

- BTrees manage their keys in sorted order and support range searches.

- BTrees require that their keys be orderable and that the ordering is
  stable. For example, the order must not change with new Python
  versions. This generally implies that the keys be of a simple type.

The database root object isn't a BTree, but is based on a persistent
dictionary. It is a bit more flexible than BTrees but isn't very
scalable.  For this reason, you don't want to use the database root
object to implement a large collection of objects, but rather use a
BTree stored in the root object (or in some other object reachable
from the root object).

We've made a number of changes to the database, but so far the changes
exist only in memory. To make the changes permanent, we need to commit
them. To do this, we use the transaction module:

    >>> import transaction
    >>> transaction.commit()

We can close and reopen the database and see that our changes are
permanent:

    >>> conn.close()
    >>> conn = ZODB.open('data.fs')
    >>> conn.books["The Two Towers"].author.name
    'J.R.R. Tolkien'

Let's add another book to the database:

    >>> author = conn.books["The Two Towers"].author
    >>> conn.books['The Hobbit'] = author.new_book("The Hobit")
    >>> conn.books["The Hobbit"].author.name
    'J.R.R. Tolkien'

We made a typo when we created the book.  We can fix it, or we can
start over.  Remember that changes aren't permanent until we commit.
We can discard changes at any time by aborting the transaction::

    >>> transaction.abort()
    >>> conn.books["The Hobbit"]
    Traceback
    ...
    Key Error: ...

Let's expand the initials in the author's name:

    >>> conn.root.authors['tolkien'].name = 'John Ronald Reuel Tolkien'

Note that we didn't use any specialized API to perform the update.  We
simply set an object attribute as we normally would without a
database.  In fact, almost all of the operations we've performed were
accomplished through normal object operations.  The only exception has
been the use of transaction ``commit`` and ``abort`` calls to indicate
that changes made should be saved or discarded.  We didn't have to keep
track of the changes made.  The ZODB did that for us.

Persistence
===========

We saw above that the ZODB keeps track of object modifications for us.
It turns out that applications have to provide some assistance.  In
many cases it's sufficient to subclass ``persistent.Persistent``, but
in some cases, some extra care is needed.  To see what's needed, we
need to understand what the basic responsibilities of peristent objects
are and how the ``Persistent`` base class helps implement those
responsibilities.

ZODB needs to know when objects are accessed so their state can be
loaded, if necessary.  The ``Persistent`` base class tracks attribute
access and causes an object's state to be loaded when needed.  For
objects implemented in Python [#c]_, this is really all that's needed
to get objects loaded.

ZODB needs to know when objects are modified so that changes are
saved.  The ``Persistent`` base class tracks attribute assignments and
marks an object as needing to be changed when attributes are
assigned. This strategy works for many persistent objects.

Care is required when a persistent object changes subobjects. Consider
an alternate, and naive author class implementation::

    class BrokenAuthor(persistent.Persistent):

        def __init__(self, id, name):
            self.id = id
            self.name = name
            self.books = {}

        def new_book(self, title):
            book = Book(title)
            book.author = self
            self.books[title] = book
            return book

In this implementation, the books attribute is a dictionary, rather
than a BTree.  The ``new_book`` method modifies author instances,
but doesn't assign an attribute, so the change isn't seen by
ZODB. This leads to the change being lost when the affected author
object is reloaded from its database.  There are 2 basic approaches
for dealing with mutable subobjects:

- Use persistent sub-objects.

  This is the recomended approach, and the approach taken by the
  ``Author`` class shown earlier.  When we use a persistent subobject,
  the containing object isn't responsible for managing the persistence
  of subobject changes; the subobject is responsible.  In the
  (non-broken) ``Author`` class, adding a book doesn't change the
  author, it changes the author's books.

- Tell ZODB about changes explicitly.

  We can tell ZODB about object changes explicitly my assigning the
  ``_p_changed`` attribute. Here's a non-broken author implementation::

    class NonBrokenAuthor(persistent.Persistent):

        def __init__(self, id, name):
            self.id = id
            self.name = name
            self.books = {}

        def new_book(self, title):
            book = Book(title)
            book.author = self
            self._p_changed = True
            self.books[title] = book
            return book

  Here we assigned ``_p_changed`` attribute to signal that the author
  object has changed.

  Note that we assigned the _p_changed attribute *before* we changed
  the books dictionary [#whychangedbefore]_.  This is subtle and one
  of the reasons we don't recommend using non-persistent mutable
  subobjects.

Finally, ZODB needs to keep track of certain meta data for persistent
objects.  The ``Persistent`` base class takes care of this too.  The
standard meta data includes:

``_p_oid``
    Every persistent object that has been stored in a database as a
    database-unique object identifier.  Before an object has been
    added to a database, the value of this attribute is None.

``_p_jar``
    The ``_p_jar`` [#jar]_ attribute is the database connection
    managing the object. If an object hasn't been stored in a
    database, then the value of this attribute is None.

``_p_serial``
    The ``_p_serial`` attribute has the identifier of the last
    transaction to update the object.  This acts as a revision
    identifier for the object.  This has a value of None if the object
    hasn't been stored yet.

``_p_changed``
    The _p_changed attribute provides access to and control of the
    changed state of an object.  It can be have one of 3 values:

    True
       The object has changed.

    False
       The object hasn't been changed.

    None
       The object's state hasn't been loaded from the database.
       (We call such objects "ghosts".)

    Typically, this attribute is used to specifically signal that an
    object has changed, as we saw earlier.

Databases, connections, and storages
====================================

ZODB separates persistent data management from low-level storage.
This allows storage implementations to vary independently from the
core persistence support.  When we create database objects in Python,
we have to supply a storage object to manage low-level database
records.

When using databases, we create database objects and then open
connections to them.  Connections allow using multiple threads within
a process to access the same database.  We'll say more about that
later in the section on concurrency.

When we began this introduction, we used a simplified API to access
our database:

    >>> conn = ZODB.connection('data.fs')

The connection function actually did three things for us:

- It instantiated a file storage

- It instantiated a database object using the storage, and

- It opened a connection to the database [#itdidmore]_.

Here's what these steps would look like if we didn't use this API::

    >>> import ZODB, ZODB.FileStorage
    >>> storage = ZODB.FileStorage.FileStorage('data.fs')
    >>> db = ZODB.DB(storage)
    >>> conn = db.open()

Why would we use the low-level APIs?  Doing so allows us greater
control.  We can supply special storage and connection options not
supported by the high-level API. The high-level API also supports only
a few standard storages.

If we want to open multiple connections, we can use a slightly
lower-level API to create a database object by passing a database file
name to ``ZODB.DB``:

    >>> db = ZODB.DB('data.fs')

Standard storages
-----------------

ZODB comes with some standard storages:

FileStorage
    File storages provide basic data storage in a single file
    [#exceptforblobs]_.  Most ZODB installations use FileStorage,
    sometimes in combination with other storages.

    To use a file storage with the high-level APIs, just pass the
    file-storage file name as a string::

       >>> db = ZODB.DB('data.fs')

ZEO
    ZEO (Zope Enterprise Objects) provides a client-server facility
    for ZODB.  ZEO allows multiple processes to share a single
    storage.  When you use ZEO, you run a ZEO storage server and
    configure your applications to use ZEO client storages to access
    your storage server. The storage server uses some underlying
    storage, such as a file storage to store data.

    The high-level API doesn't support ZEO yet, but ZEO provides its
    own high-level API.  To use a ZEO client storage with the ZEO
    high-level APIs, just pass the ZEO server address as a host and
    port tuple or as an integer port on the local host::

       >>> db = ZEO.DB(('storage.example.com', 8100))
       >>> connection = ZEO.connection(8100) # localhost

MappingStorage
    Mapping storages store database records in memory.  Mapping
    storages are typically used for testing or experimenting with
    ZODB.

    A goal of MappingStorage is to provide a fairly simple storage
    implementation to study when learning how to implement storages.

    To use a mapping storage with the high-level APIs, just pass
    None::

       >>> connection = ZODB.connection(None)

DemoStorage
    Demo storages allow you to take an unchanging base storage and
    store changes in a separate changes storage.  They were originally
    implemented to allow demonstrations of applications in which a
    populated sample database was provided on Compact Disk and users
    could make changes that were stored in memory.

    Demo storages don't actually store anything themselves. They
    delegate to 2 other storages, an unchanging base storage and a
    storage that holds changes.  This is an example of a storage
    wrapper.  It's common to compose storages from base storages and
    one or more storage wrapper.

3rd-party storages
------------------

There are a number of 3rd-party storages.  Writing additional storage
implementations relatively straightforward.  Here are some examples of
3rd-party storage implementations:

RelStorage
    RelStorage stores data in relational databases.

zc.beforestorage
    zc.beforestorage is a storage wrapper that provides a snapshot of
    an underlying storage at a moment of time.  This is useful because
    it can take changing storage, like a ZEO client storage and freeze
    it at a point in time, allowing it to be used as a base for a demo
    storage.

zc.zlibstorage
    zc.zlibstoprage provides a wrapper storage to compress database
    records.

zc.zrs and zeoraid
    zc.zrs and zeoraid provide database replication.  zc.zrs is a
    commercial storage implementation, while zeoraid is open source.

Configuration strings
---------------------

ZODB supports the use of textual configuration strings to define
databases, storages, and ZEO servers.  Production applications
typically create database objects by loading configuration strings
from application configuration files [#zconfig]_.

To create a database from a configuration string, use the
``ZODB.config.databaseFromString`` function.  Here's an example that
creates a database using a file storage::

    >>> import ZODB.config
    >>> db = ZODB.config.databaseFromString("""
    ... <zodb>
    ...     <filestorage>
    ...         path data.fs
    ...     </filestorage>
    ... </zodb>
    ... """)

The configuration syntax was inspired by the Apache configuration
syntax. Configuration sections are bracketed by opening and closing
typed tags and can be nested. Options are given as names and values
separated by spaces.

In the example above, a ``zodb`` tag defines a database object
[#multipledbtags]_.  It contains a ``filestorage`` tag and this uses a
file storage at the path ``data.fs``.

To find out about the database options supported by the ``zodb`` tag,
see the database reference documentation. To find out about storage
options, see the storage reference documentation.

Concurrency
===========

ZODB supports accessing databases from multiple threads, including
threads in separate processes.  This is accomplished using per-thread
database connections and transaction managers.  Each thread operates
as if it has it's own copy of the database.  Threads are synchonized
through transaction commits.

In a typical application, each thread opens a separate connection to a
database.  Each connection has it's own object cache. If multiple
connections access the same object, they each get their own
copy. Let's look at an example:

   >>> conn1 = db.open()
   >>> author1 = conn1.root.authors['tolkien']

   >>> conn2 = db.open()
   >>> author2 = conn1.root.authors['tolkien']

Here we've opened two connections and fetched the author object for
J.R.R. Tolkien. From a database perspective, these are the same
objects:

    >>> author1._p_oid == author2._p_oid
    True

    >>> author1.name
    'J.R.R. Tolkien'
    >>> author2.name
    'J.R.R. Tolkien'

But they're different Python objects:

    >>> author1 is author2
    False

If we modify one, we don't see the change in the other:

    >>> author1.name = 'John Ronald Reuel Tolkien'
    >>> author2.name
    'J.R.R. Tolkien'

Until we commit the change:

    >>> transaction.commit()
    >>> author2.name
    'John Ronald Reuel Tolkien'

Transaction managers
--------------------

When we use ``transaction.commit()`` to finish a transaction, we're
interacting with a transaction manager. There is a transaction manager
per thread, and by default ZODB uses the current thread's transaction
manager.

The example in the last section was a little odd, because the two
connections shown were in the same thread and therefore used the same
transaction manager.  That's why the transaction commit affected both
connections.

Applications can create and manage their own transaction managers.
This isn't commonly done, except in tests, but we'll do it below to
illustrate more carefully the normal isolation of application threads.

We close the second connection and reopen it with a separate
transaction manager:

    >>> conn2.close()
    >>> transaction_manager2 = transaction.TransactionManager()
    >>> conn2 = db.open(transaction_manager2)

Now, we'll change the author name back to what we had before:

    >>> author1.name = 'J.R.R. Tolkien'
    >>> transaction.commit()

    >>> author2.name
    'John Ronald Reuel Tolkien'

Even though we committed the transaction, we didn't see the update
reflected in the second connection.  This is because the second
connection is now using a different transaction manager, as would
be the case if it was runnning in a separate thread.

To see the change in the second transaction, we need to end it's
current transaction.  Because we didn't make any changes in the second
connection, we can use abort or commit to end the transaction.

    >>> transaction_manager2.commit()
    >>> author2.name
    'J.R.R. Tolkien'

Conflicting changes
-------------------

When multiple threads modify the same object, this is considered a
conflict. Generally, when there's a conflict, the first thread to
commit it's changes will win and other threads will have to be redone.
For example, let's look at what happens when we change the auther name
in both connections:

    >>> author1.name = 'John Ronald Reuel Tolkien'
    >>> author2.name = 'John Tolkien'
    >>> transaction.commit()
    >>> transaction_manager2.commit()

Here, we get a conflict error when we commit the changes made in the
second connection, because the conflict with changes made in the
first.  If we want to make the second change, we need to abort the
transaction and redo it:

    >>> transaction_manager2.abort()
    >>> author2.name = 'John Tolkien'
    >>> transaction_manager2.commit()

Conflicts are annoying for 2 reasons:

- Application code has to anticipate conflicts and be prepared to
  retry transactions.

- Retrying transactions is ususally expensive, hurting application
  responsiveness and throughput.

There are a number of ways to avoid conflicts:

- Organize application threads and data structures so that objects are
  unlikely to be modified by multiple threads at the same time.

- Use data structures that support conflict resolution.

Conflict resolution
-------------------

An object can provide logic to sort out conflicting changes, allowing
conflicting changes to be committed. This is one of the advantages of
BTrees.  Usually, when different BTree keys are modified in different
threads, the conflicting changes can be resolved.  This allows
books to be added to authors at the same time:

    >>> book1 = author1.new_book['The Silmarillion']
    >>> conn1.root.books['The Silmarillion'] = book1

    >>> book2 = author1.new_book['The Children of Hurin']
    >>> conn2.root.books['The Children of Hurin'] = book2

    >>> transaction.commit()
    >>> transaction_manager2.commit()

    >>> import pprint
    >>> pprint.pprint(list(author2.books))

Handling conflict errors and retrying transactions
--------------------------------------------------

When a conflict error arises, the current transaction must be
aborted.  Generally, then, the transaction will need to be
retried. The transaction package provides some facilities that help
automate this process.

Transaction managers and the transaction package itself can be used
with the Python with statement, as in::

    with transaction:
        author2.name = 'John Tolkien'

The suite inside the with statement is executed. If there is no error,
the transaction is committed. If there is an exception, the
transaction is automatically aborted.

Transaction managers and the transaction package also provide an
``attempts`` method.  The attempts method helps with handling
transient errors, like conflict errors.  It returns an iterator that
provides up to a given number of attempts to perform a transaction::

    for attempt in transaction.attemps(5):
        with attempt:
            author2.name = 'John Tolkien'

The example above tries up to 5 times to set the author name.  If an
attempt suceeds, the loop exits.  If there are non-transient errors,
the the loops exits by raising the error.  If transient errors are
raised, the attempts continue until an attempt suceeds, or until the
number of attempts is exhaused, at which point the loops exits with by
raising transient error.

Object life cycle
=================

In-memory Persistent objects transition through a number of states, as
shown in figure 1.

.. image:: object-life-cycle.png

Objects are created in the new state.  At this point, they behave like
normal Python objects.

To add an object to a database, you add a reference to it from an
object that's already in the database and commit the change. At that
point the object is in the saved state.

If you modify the object, it transitions to the changed state until
the transaction ends.

The ghost state is a state in which an object exists in memory but
lacks any data.  When an object hasn't been used in a while and ZODB
needs to make room for new objects, it is deactivated and it's data is
released. The object itself remains in memory as a ghost as long as it
is refered to by other objects.

When an object is no-longer referenced, it is removed from memory by
the Python garbage collector.  Because object data may include
references to other persistent objects, releasing an object's data may
cause referenced objects to become collected by the Python garbage
collector and removed from memort.

When an object's data are loaded, references to other object's in the
object's data cause those objects to be loaded. When an object is
loaded, it is in the ghost state until it is accessed, at which point
it's data are loaded and it transitions to the saved state.

If an object is in the saved state, it can be deactivated at any
time.  This is why care must be taken when tracking changes
yourself. Consider another broken author implementation::

    class SubtlyBrokenAuthor(persistent.Persistent):

        def __init__(self, id, name):
            self.id = id
            self.name = name
            self.books = {}

        def new_book(self, title):
            book = Book(title)
            book.author = self
            self.books[title] = book
            self._p_changed = True
            return book

In this version of the author class, ``_p_changed`` is set after the
books dictionary if modified.  In theory [#practicemorecomplicated]_,
the author object could be deactivated after the ``books`` dictionary
is modified and before ``_p_changed`` is set, in which case, the
change to the ``books`` would be lost.

Remember that the object life cycle described here refers to a single
instance of a database object. There can be multiple instances of a
single database object in memory, in different states, at once.

Memory management
=================

One of the advantages of using a database is that you can deal with
more data than will fit in memory.  ZODB takes care of loading objects
into memory when needed and removing them from memory when no-longer
needed.  More precisely, ZODB moves persistent objects in and out of
memory.  The persistent object is the unit of storage.

In the book example, Each book and author is in it's own database
record.  Because author's books are managed in BTrees, which are
persistent objects, the book collections aren't contained in the
author database records. Rather the author records contain persistent
references to the BTree records.

As they grow, BTrees spread their data over multiple persistent
sub-objects.  This makes BTrees highly scalable.  You can have BTrees
that store many millions of items and load only a small fraction of
the BTree into memory to look an item up.

It's important to choose data structures carefully to prevent
individual persistent objects from becoming too large. A naive choice
of object class can lead to a database in which all of the data
resides in a single database object, im which case, the entire
database must remain in memory.

Each ZODB connection has an in-memory cache. You can set the size of
this cache as a number of objects, a number of bytes, or both.  While
these sizes are limits, they are only checked at certain times and, as
a result, can be exceeded.

Blobs: managing files in ZODB
=============================

ZODB was originally developed to support the Zope web application
frameworks. Web applications often need to manage files of static
data, such as images, movies, and other resource files.  Especially
for large media files, loading data into memory just to hand it off to
a web client is counter productive.  To address cases like these, ZODB
provides blobs. "BLOB" is a term borrowed from other databases and
is an acronyme for "binary large object".  A better term might have
been something like, "persistent file".

ZODB blobs are persistent objects that can be opened to obtain Python file
objects to access their data. Like other persistent objects,
modifications to blobs are managed transactionally.

Blobs are created using the ``ZODB.blob.Blob`` class
[#nosubclassingBlob].  Let's update our book class to hold electronic
versions of the book::


    import persistent, BTrees.OOBTree, ZODB.blob

    class Book(persistent.Persistent):
        def __init__(self, title):
            self.title = title
            self.electronic = BTrees.OOBTree()

        def add_electronic(self, format, data):
            version = self.electronic.get(format)
            if version is None:
                version = self.electronic[format] = ZODB.blob.Blob()
            version.open('w')
            version.write(data)
            version.close()

        def get_electronic(self, format):
            return self.electronic[format].open()

Now books manage electronic binary versions.  We add or update a
version using the ``add_electronic`` method.  It checks to see if
there is already an alectronic version of a book and, if there isn't,
it creates one using ``ZODB.blob.Blob()``.

The ``add_electronic`` method then opens the blob, passing the write
flag, ``'w'``.  No file name is passed to the open method. The blob
object itself identified the file to open. As with the built-in open
function, the ``'w'`` flag causes any existing data to be
overwritten. The open statement returns a file object that can be used
with anything that expects a Python file object [#filesubclass]_.  The
``add_electronic`` method simply calls it's ``write`` method to write
the data passed in and then closes it.

The ``get_electronic`` method is used to access a binary version. It
simply opens the blob for the given format and returns the resulting
file. No mode is passed, so the default mode, ``'r'`` is used.

Several modes are supported by the open statement:

``'r'``
   Open for reading.  The file returned includes any changes made in
   the current transaction.

``'c'``
   Open committed data for reading.  The file returned does *not*
   reflect any changes made in the current transaction.

``'w'``
   Open for writing. Existing data are overridden.

``'a'``
   Open for appending. Existing data are preserved and data are
   written at the end of the file.

``'r+'``
   Open for writing without overwriting existing data.  Depending on
   file position, new writes may overwrite existing data.

As mentioned at the beginning of this section, a motivation for blobs
os to avoid loading large amounts of binary data into memory.  Our
``add_electronic`` implementation requires that the entire file
content be passes as a string. A better implemention would copy data
from a file in blocks::

        def add_electronic(self, format, source_file):
            version = self.electronic.get(format)
            if version is None:
                version = self.electronic[format] = ZODB.blob.Blob()
            version.open('w')
            while 1:
                data = source_file.read(4096)
                if not data:
                    break
                version.write(data)

            version.close()

If the source file is a temporary file [#temporaryfiletobeconsumed]_,
we can pass it's name to the blob ``consumeFile`` method::

        def add_electronic(self, format, source_file_name):
            version = self.electronic.get(format)
            if version is None:
                version = self.electronic[format] = ZODB.blob.Blob()
            version.consumeFile(source_file_name)

The advantage of ``consumeFile`` is that it can avoid copying the
source file [#whencanitavoidcopying]_.

To use blobs, you have to enable blobs when you configure your
storage, generally by naming a blob directory::

    >>> conn = ZODB.open('data.fs', blob_dir='data.blobs')

database maintenamce
====================

Packing
-------

Garbage Collection
------------------

Multiple databases
==================

Indexing
========

Object-oriented versus relational designs
=========================================

time travel
===========

















.. [#root] The root attribute actually returns a convenience wrapper
   around the root object.  See "More on the root object".

.. [#c] Implementing objects in C requires a lot more care. It's
   really hard. :) See "Implementing persistent objects in C" for more
   details.

.. [#whychangedbefore] We'll explain why this is important later,
   when we talk about object lifecycles.

.. [#jar] The name ``_p_jar`` comes from early implementations of ZODB
   in which databases were called "pickle jars", because objects were
   stored using the Python pickle format.  In those early versions,
   there weren't separate database connections.

.. [#itdidmore] It also arranged that when we closed the connection,
   the underlying database was closed.

.. [#exceptforblobs] If blobs are used, each blob is stored in a
   separate file.

.. [#zconfig] ZODB uses the ``ZConfig`` configuration
   system. Applications that use ``ZConfig`` can also merge the ZODB
   configuration schemas with their own configuration schemas.

.. [#multipledbtags] You can define multiple databases, so there can
   be multiple ``zodb`` tags. See "Using multiple databases."

.. [#practicemorecomplicated] In fact, the object wouldn't be
   deactivated unless some computation caused another object to be
   loaded and maybe not even then, depending on other factors. Suffice
   it to say that you don't want to have to think that hard.

.. [#nosubclassingBlob] The Blob class can't be subclassed. To
   associate behavior with blobs, use composition.

.. [#filesubclass] The object returned is an instance of a subclass of
   the standard Python file type.

.. [#temporaryfiletobeconsumed] The file might be the result of a web
   file upload. It must be named.

.. [#whencanitavoidcopying] The blob will attempt to rename the file
   to the blob directory.  This is generally only possible when the
   file is in the same disk partition as the blob directory.

