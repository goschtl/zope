Avoiding cache verifification
=============================

For large databases it is common to also use very large ZEO cache
files.  If a client has beed disconnected for too long, cache verification
might be necessary, but cache verification can be very hard on the
storage server.

ClientStorage provides an option to drop it's cache rather than doing
verification.  When this option is used, and verification would be
necessary, ClientStorage:

- Invalidates all object caches

- Drops or clears it's client cache. (The end result is that the cache
  is working but empty.)

- Logs a CRITICAL message.

- Publishes a ZEO.interfaces.CacheDroppedEvent event.

Here's an example that shows that this is actually what happens.

Start a server, create a cient to it and commit some data

    >>> addr, admin = start_server(keep=1)
    >>> import ZEO, transaction
    >>> db = ZEO.DB(addr, drop_cache_rather_verify=True, client='cache',
    ...             name='test')
    >>> wait_connected(db.storage)
    >>> conn = db.open()
    >>> conn.root()[1] = conn.root().__class__()
    >>> conn.root()[1].x = 1
    >>> transaction.commit()
    >>> len(db.storage._cache)
    3

Now, we'll stop the server and restart with a different address:

    >>> stop_server(admin)
    >>> addr2, admin = start_server(keep=1)

And create another client and write some data to it:

    >>> db2 = ZEO.DB(addr2)
    >>> wait_connected(db2.storage)
    >>> conn2 = db2.open()
    >>> for i in range(5):
    ...     conn2.root()[1].x += 1
    ...     transaction.commit()
    >>> db2.close()
    >>> stop_server(admin)

Now, we'll restart the server.  Before we do that, we'll capture
logging and event data:

    >>> import logging, zope.testing.loggingsupport, zope.event
    >>> handler = zope.testing.loggingsupport.InstalledHandler(
    ...     'ZEO.ClientStorage', level=logging.ERROR)
    >>> events = []
    >>> zope.event.subscribers.append(events.append)

Now, we'll restart the server on the original address:

    >>> _, admin = start_server(zeo_conf=dict(invalidation_queue_size=1),
    ...                         addr=addr, keep=1)
    >>> wait_connected(db.storage)

Now, let's verify our assertions above:
  
- Drops or clears it's client cache. (The end result is that the cache
  is working but empty.)

    >>> len(db.storage._cache)
    0

- Invalidates all object caches

    >>> transaction.abort()
    >>> conn.root()._p_changed

- Logs a CRITICAL message.

    >>> print handler
    ZEO.ClientStorage CRITICAL
      test dropping stale cache

    >>> handler.clear()

- Publishes a cache-dropped event.

    >>> for e in events:
    ...     print e.__class__.__name__
    CacheDroppedEvent

    >>> del events[:]

If we access the root object, it'll be loaded from the server:

    >>> conn.root()[1].x
    6

    >>> len(db.storage._cache)
    2

Similarly, if we simply disconnect the client, and write data from
another client:

    >>> db.close()

    >>> db2 = ZEO.DB(addr)
    >>> wait_connected(db2.storage)
    >>> conn2 = db2.open()
    >>> for i in range(5):
    ...     conn2.root()[1].x += 1
    ...     transaction.commit()
    >>> db2.close()

    >>> db = ZEO.DB(addr, drop_cache_rather_verify=True, client='cache',
    ...             name='test')
    >>> wait_connected(db.storage)
    
  
- Drops or clears it's client cache. (The end result is that the cache
  is working but empty.)

    >>> len(db.storage._cache)
    1

(When a database is created, it checks to make sure the root object is
in the database, which is why we get 1, rather than 0 objects in the cache.)

- Logs a CRITICAL message.

    >>> print handler
    ZEO.ClientStorage CRITICAL
      test dropping stale cache

    >>> handler.clear()

- Publishes a cache-dropped event.

    >>> for e in events:
    ...     print e.__class__.__name__
    CacheDroppedEvent

If we access the root object, it'll be loaded from the server:

    >>> conn = db.open()
    >>> conn.root()[1].x
    11

    >>> db.close()
