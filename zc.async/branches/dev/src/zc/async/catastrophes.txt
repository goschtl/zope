Recovering from Catastrophes
============================

------------
Introduction
------------

Sometimes bad things happen in the course of processing tasks. What might go
wrong? How does zc.async handle these errors? What are your responsibilities?

First, what might go wrong?

- zc.async could have a problem while polling for jobs.  We'll call this a
  "polling exception."

- zc.async could have a problem while performing a particular job.  We'll call
  this a "job-related exception."

For the purpose of this discussion, we will omit the possibility that zc.async
has a bug. That is certainly a possibility, but the recovery story is not
predictable, and if we knew of a bug, we'd try to fix it, rather than discuss
it here!

Exploring polling exceptions and job related exceptions will illuminate the
more specific catastrophes you may encounter, and how your code and zc.async's
can work together to handle them.  We'll discuss each, then drill down into
some specific scenarios.

Polling Exceptions
------------------

Polling exceptions are, at least in theory, the least of your worries. You
shouldn't have to worry about them; and if you do, it is probably a basic
configuration problem that you need to address, such as making sure that the
dispatcher process has access to the needed databases and software; or making
sure that the dispatcher process is run by a daemonizing software that will
restart if needed, such as zdaemon (http://pypi.python.org/pypi/zdaemon) or
supervisor (http://supervisord.org/).

zc.async is largely responsible for dealing with polling exceptions. What does
it have to handle?

- The process running the poll ends, perhaps in the middle of a poll.

- zc.async cannot commit a transaction during the poll, for instance because of
  a ConflictError, or because the database is unavailable.

What needs to happen to handle these problems?

Process Ends
............

If the process ends, your daemonizing front-end (zdaemon, supervisor, etc.)
needs to restart it. The ZODB will discard incomplete transaction data, if any.

The only thing a zc.async dispatcher needs to handle is clean up.

- Ideally it will be able to deactivate its record in the ZODB during the
  process shutdown.

- Instead, if it was a "hard crash" that didn't allow deactivation, a sibling
  dispatcher will realize that the dispatcher is down and deactivate it.

- Or, finally, if it was a hard crash without a sibling, and the daemon
  restarts a process for the original dispatcher instance, the new process
  needs to realize that the old process is dead, not competing with it.

Transaction Error
.................

If the poll gets a conflict error, it should simply abort and retry the poll,
forever, with a small back-off.

If the database goes away (perhaps the ZEO server goes down for a bit, and the
ZEO client to which the dispatcher is connected is trying to reconnect) it
should gracefully try to wait for the database to return, and resume when it
does.

Other, more dramatic errors, such as POSKey errors, are generally considered to
be out of zc.async's domain and control. It should ideally continue to try to
resume as long as the process is alive, in case somehow the situation improves,
but this may be difficult and the expectations for zc.async's recovery are
lower than with ConflictErrors and ClientDisconnected errors.

Summary of Polling Exceptions
.............................

To repeat, then, polling exceptions have two basic scenarios.

If a dispatcher process ends, it needs to deactivate its record in the ZODB, or
let another process know to deactivate it.

If a ZODB.POSException.ConflictError occurs, retry forever with a small
backoff; or if ZEO.Exceptions.ClientDisconnected occurs, retry forever with a
small backoff, waiting for the database to come back.

Most anything else will ideally keep zc.async attempting to re-poll, but it may
not happen: expectations are lower.

Job-Related Exceptions
----------------------

What about job-related exceptions? Responsibility for handling job-related
exceptions is shared between your code and zc.async's.  What might happen?

- Your job might fail internally.

- The process running your task ends before completing your task.

- zc.async cannot commit a transaction after your task completes, for instance
  because of a ConflictError, or because the database is unavailable.

What should occur to handle these problems?

Job Fails
.........

As discussed elsewhere, if your job fails in your own code, this is mostly
your reponsibility. You should handle possible errors both within your job's
code, and in callbacks, as appropriate. zc.async's responsibilities are merely
to report.

By default, zc.async will log a failure of a job entered in a queue at the
"ERROR" level in the ``zc.async.events`` log, and it will log a failure of a
callback or other internal job at the "CRITICAL" level. This can be controlled
per-process and per-job, as we'll see below. These tracebacks include
information about the local and global variables for each frame in the stack,
which can be useful to deduce the problem that occurred.

zc.async also includes a ``Failure`` object on the job as a result, to let you
react to the problem in a callback, and analyze it later.  This is discussed in
detail elsewhere.

The RetryPolicy, discussed later, can try to react to exceptions from the job's
code, but the default policies included in the package do not.

Process Ends
............

If a process ends while it is performing a job, that is similar, in large part,
to the possibility of the process ending the polling job: we need to restart
the process, and realize that we had started the job. But should we restart the
job, or abort it?

Answering this question is a matter of policy, and requires knowing what each
job does.

Generally, if a job is fully transactional, such as writing something to the
ZODB, and the job has not timed out yet, you'll want to restart it. You might
want to restart some reasonably large number of times, and then suspect that,
since you can't seem to finish the job, maybe the job is causing the process to
die, and you should abort.  Or perhaps you want to restart for ever.

If the job isn't transactional, such as communicating with an external service,
you might want to abort the job, and set up some callbacks to handle the
fallout.

As we'll see below, zc.async defaults to guessing that jobs placed directly in
a queue are transactional, and can be restarted up to ten times; and that jobs
used as callbacks are also transactional, and should be restarted until they
succeed.  The defaults can be changed and the behavior of an individual
job can be changed.

These settings are controlled with a RetryPolicy, discussed below.

Transaction Error
.................

Handling transaction errors after processing a job is also similar to the
handling of transaction errors for polling exceptions. ConflictErrors and
ClientDisconnected errors should often cause jobs to be aborted and restarted.
However, if the job is not transactional, such as communicating with an
external service, a simple abourt and retry may be hazardous. Also, many jobs
should be stopped if they retry on ConflictError more than some heuristic
bellweather, with the logic that they may be simply doing something too
problematic, and they are blocking other tasks from starting. But other jobs
should be retried until they complete.

As mentioned above, zc.async defaults to guessing that jobs are transactional.
Client Disconnected errors are retried forever.  Jobs placed in a queue retry
ConflictErrors five times, while callbacks retry them forever, with a small
backoff.  The defaults can be changed and the behavior of an individual
job can be changed, using the RetryPolicy described below.

While custom RetryPolicies can try to handle other transaction errors, they are
generally considered to be out of zc.async's domain and control.

Summary of Job-Related Exceptions
.................................

If an exception handles in your job's code, zc.async will log it as an ERROR
if a main queue job and as CRITICAL if it is a callback; and it will make the
result of the call a ``Failure`` with error information, as shown elsewhere.
Everything else is your responsibility, to be handled with try:except or
try:finally blocks in your code, callbacks, or custom RetryPolicies.

Process death, conflict errors, and ``ClientDisconnected`` errors all may need
to be handled differently for different jobs. zc.async has a default policy for
jobs placed in a queue, and for callback jobs. The default policy, a
RetryPolicy, can be changed and can be set explicitly per-job.

Your Responsibilities
---------------------

As the author of a zc.async job, your responsibilities, then, are to handle
your own exceptions; and to make sure that the retry policy for each job is
appropriate.  This is controlled with an IRetryPolicy, as shown below.

As someone configuring a running dispatcher, you need to make sure that you
give the dispatcher the necessary access to databases and software to perform
your jobs, and you need to review (and rotate!) your logs.

zc.async's Responsibilities
---------------------------

zc.async needs to have polling robust in the face of restarts, ConflictErrors
and ClientDisconnected errors. It needs to give your code a chance to decide
what to do in these circumstances, and log your errors.

Retry Policies
--------------

The rest of the document uses scenarios to illustrate how zc.async handles
errors, and how you might want to configure retry policies.  Retry policies are
given a job, and then exception information, and then can determine whether
zc.async should retry the job. zc.async comes with three retry policies.

- One is the absence of a retry policy: do not retry this job.  A value of
  ``None`` represents this policy.  This is appropriate for tasks that are
  not transactional.  They typically need to be handled with a callback.

- The default is a retry policy that retries after a restart up to four times,
  retries a ConflictError up to four times, and retries a ClientDisconnected up
  to four times.

- One is a retry policy that never gives up on restarts, ConflictErrors, or
  ClientDisconnected errors: it has no limit but keeps trying forever.

Scenarios
---------

We'll examine a number of scenarios, many of which combine problems in polling
and in jobs.  In these scenarios, we'll refer to a job that was placed directly
in a queue as a "queue job".  A job that was performed in any other way is a
"callback job," because most often these are callbacks.

- Polling errors

  * The system is polling and gets a ConflictError.

  * The system is polling and gets a ClientDisconnected error.

- Internal job errors

  * A worker process is polling and working on a queue job. The queue job fails
    internally.

  * A worker process is polling and working on a callback job.  The callback job
    fails internally.

- Default retry policy

  * A worker process is working on a job with the default retry policy and gets
    a ConflictError during the commit.
  
  * A worker process is working on a job with the default retry policy and gets
    a ClientDisconnected error.
  
  * A worker process is working on a job with the default retry policy. The
    process dies gracefully and restarts.
  
  * Like the previous scenario, a worker process is working on a job with the
    default retry policy. The process crashes hard (does not die gracefully)
    and restarts.
  
  * Like the previous scenario, a worker process is working on a job with the
    default retry policy. The process crashes hard (does not die gracefully)
    and a sibling notices and takes over.

- No retry policy

  * A worker process is working on a job without a retry policy (that is,
    zc.async should not retry it) and gets a ConflictError during the commit.
  
  * A worker process is working on a job without a retry policy (that is,
    zc.async should not retry it) and gets a ClientDisconnected error.
  
  * A worker process is working on a job with no retry policy (that is,
    zc.async should not retry it). The process dies gracefully and restarts.
  
  * Like the previous scenario, a worker process is working on a job with no
    retry policy (that is, zc.async should not retry it). The process crashes
    hard (does not die gracefully) and restarts.
  
  * Like the previous scenario, a worker process is working on a job with no
    retry policy (that is, zc.async should not retry it). The process crashes
    hard (does not die gracefully) and a sibling notices and takes over.

- Retry forever policy

  * A worker process is working on a job with the retry-forever policy and gets
    a ConflictError during the commit.
  
  * A worker process is working on a job with the retry-forever policy and gets
    a ClientDisconnected error.
  
  * A worker process is working on a job with the retry-forever policy. The
    process dies gracefully and restarts.
  
  * Like the previous scenario, a worker process is working on a job with the
    retry-forever policy. The process crashes hard (does not die gracefully)
    and restarts.
  
  * Like the previous scenario, a worker process is working on a job with the
    retry-forever policy. The process crashes hard (does not die gracefully)
    and a sibling notices and takes over.

We will close with customizations:

- custom retry policies, particularly for non-transactional tasks;

- changing the default retry policy, per-process and per-agent; and

- changing the default log level for queue jobs, callback jobs, and per-job.

-------------------------
Scenarios: Polling Errors
-------------------------

ConflictError
-------------

A common place for a conflict error is with two dispatchers trying to claim the
same job from the queue.  This example will mimic that situation.

Imagine we have a full set up with a dispatcher, agent, and queue. [#setUp]_
We'll actually replace the agent's chooser with one that behaves badly: it
blocks, waiting for our lock.

    >>> import threading
    >>> lock1 = threading.Lock()
    >>> lock2 = threading.Lock()
    >>> lock1.acquire()
    True
    >>> lock2.acquire()
    >>> def acquireLockAndchooseFirst(agent):
    ...     res = agent.queue.claim()
    ...     if res is not None:
    ...         lock2.release()
    ...         lock1.acquire()
    ...     return res
    ...
    >>> import zc.async.instanceuuid
    >>> import zc.async.interfaces
    >>> import transaction
    >>> _ = transaction.begin()
    >>> queues = root[zc.async.interfaces.KEY]
    >>> queue = queues['']
    >>> da = queue.dispatchers[zc.async.instanceuuid.UUID]
    >>> agent = da['main']
    >>> agent.chooser = acquireLockAndchooseFirst
    >>> def returnSomething():
    ...     return 42
    ...
    >>> job = queue.put(returnSomething)
    >>> transaction.commit()

Now, when the agent tries to get our job, we'll start and commit another
transaction that removes it from the queue.  This will generate a conflict
error for the poll's thread and transaction, because it cannot also remove the
same job.

    >>> lock2.acquire()
    >>> _ = transaction.begin()
    >>> job is queue.pull()
    True
    >>> transaction.commit()
    >>> lock1.release()

However, the ConflictError is handled, and polling continues.

    >>> _ = transaction.begin()
    >>> import zc.async.agent
    >>> agent.chooser = zc.async.agent.chooseFirst
    >>> transaction.commit()
    >>> import zc.async.dispatcher
    >>> dispatcher = zc.async.dispatcher.get()
    >>> import zc.async.testing
    >>> zc.async.testing.get_poll(dispatcher)

And if we put the job back, it will be performed.

    >>> job is queue.put(job)
    True
    >>> transaction.commit()
    >>> zc.async.testing.wait_for_result(job)
    42

Client Disconnected
-------------------

The story is very similar if the ZEO connection goes away for a while.  We'll
mimic a ZEO ClientDisconnected error by monkeypatching
transaction.TranasctionManager.commit.

    >>> lock1.locked()
    True
    >>> lock2.locked()
    True

    >>> job = queue.put(returnSomething)
    >>> transaction.commit()

    >>> lock2.acquire()
    >>> import ZEO.Exceptions
    >>> def commit(self):
    ...     raise ZEO.Exceptions.ClientDisconnected()
    ...
    >>> import transaction
    >>> old_commit = transaction.TranasctionManager.commit
    >>> transaction.TranasctionManager.commit = commit
    >>> lock1.release()
    >>> zc.async.testing.get_poll(dispatcher)
    >>> transaction.TranasctionManager.commit = old_commit
    >>> zc.async.testing.wait_for_result(job)
    42

Here's another variant that mimics being unable to read the storage during a
poll, and then recouperating.

    >>> error_raised = 0
    >>> def raiseDisconnectedThenChooseFirst(agent):
    ...     if not error_raised:
    ...         raise ZEO.Exceptions.ClientDisconnected()
    ...     return agent.queue.claim()
    >>> agent.chooser = raiseDisconnectedThenChooseFirst
    >>> def returnSomething():
    ...     return 42
    ...
    >>> job = queue.put(returnSomething)
    >>> transaction.commit()
    >>> zc.async.testing.get_poll(dispatcher)
    >>> zc.async.testing.wait_for_result(job)
    42

------------------------------
Scenarios: Internal Job Errors
------------------------------

Queue Job
---------

Callback Job
------------

-------------------------------
Scenarios: Default Retry Policy
-------------------------------

ConflictError
-------------

ClientDisconnected
------------------

Graceful Shutdown
-----------------

Hard Crash
----------

Hard Crash and Sibling
----------------------

--------------------------
Scenarios: No Retry Policy
--------------------------

ConflictError
-------------

ClientDisconnected
------------------

Graceful Shutdown
-----------------

Hard Crash
----------

Hard Crash and Sibling
----------------------

-------------------------------
Scenarios: Retry-Forever Policy
-------------------------------

ConflictError
-------------

ClientDisconnected
------------------

Graceful Shutdown
-----------------

Hard Crash
----------

Hard Crash and Sibling
----------------------

--------------
Customizations
--------------

Changing the Default Retry Policy
---------------------------------

Creating a New Retry Policy
---------------------------

Changing the Log Level
----------------------










.. ......... ..
.. Footnotes ..
.. ......... ..

.. [#setUp]

    >>> import ZODB.FileStorage
    >>> storage = ZODB.FileStorage.FileStorage(
    ...     'main.fs', create=True)
    >>> from ZODB.DB import DB 
    >>> db = DB(storage) 
    >>> conn = db.open()
    >>> root = conn.root()
    >>> import zc.async.configure
    >>> zc.async.configure.base()
    >>> import zc.async.subscribers
    >>> import zope.component
    >>> zope.component.provideHandler(zc.async.subscribers.queue_installer)
    >>> zope.component.provideHandler(
    ...     zc.async.subscribers.ThreadedDispatcherInstaller(
    ...         poll_interval=0.5))
    >>> zope.component.provideHandler(zc.async.subscribers.agent_installer)
    >>> import zope.event
    >>> import zc.async.interfaces
    >>> zope.event.notify(zc.async.interfaces.DatabaseOpened(db))
    >>> import transaction
    >>> _ = transaction.begin()

    >>> import time
    >>> def wait_for_start(job):
    ...     for i in range(60):
    ...         t = transaction.begin()
    ...         if job.status == zc.async.interfaces.ACTIVE:
    ...             break
    ...         time.sleep(0.1)
    ...     else:
    ...         assert False, 'job never started'

    >>> def wait_to_deactivate(dispatcher):
    ...     for i in range(60):
    ...         if dispatcher.activated == False:
    ...             break
    ...         time.sleep(0.1)
    ...     else:
    ...         assert False, 'dispatcher never deactivated'